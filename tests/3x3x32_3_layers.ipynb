{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000 Iterations per layer\n",
    "\n",
    "3 Layers\n",
    "\n",
    "3x3 convolutions (32 per layer)\n",
    "\n",
    "\"Complete\" graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-28T20:29:37.231273",
     "start_time": "2017-04-28T20:29:36.828389"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "from numba import jit\n",
    "import time\n",
    "\n",
    "def weight_variable(shape, name):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def conv2d(x, W, name):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME', name=name)\n",
    "\n",
    "def max_pool_2x2(x, name):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME', name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-28T20:29:38.779946",
     "start_time": "2017-04-28T20:29:37.810909"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-28T20:37:43.730586",
     "start_time": "2017-04-28T20:37:41.847228"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Layer1(num_filters,iters = 100):\n",
    "    t0 = time.time()\n",
    "    with tf.Graph().as_default() as g:\n",
    "        x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "        D0 = tf.reshape(x, [-1,28,28,1])\n",
    "        y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "        dropout = tf.placeholder(tf.float32)\n",
    "        \n",
    "        # Conv1\n",
    "        W_conv1 = weight_variable([3,3,1,num_filters], \"W_conv1\")\n",
    "        b_conv1 = bias_variable([num_filters], \"b_conv1\")\n",
    "        h_conv1 = tf.nn.relu(conv2d(D0, W_conv1, \"h_conv1\") + b_conv1)\n",
    "        h_conv1_drop = tf.nn.dropout(h_conv1, dropout)\n",
    "\n",
    "        # FC\n",
    "        fc1_flat = tf.contrib.layers.flatten(h_conv1_drop)\n",
    "        \n",
    "        W_fc1 = weight_variable([int(fc1_flat.get_shape()[1]), 10], \"W_fc1\")\n",
    "        b_fc1 = bias_variable([10], \"b_fc1\")\n",
    "\n",
    "        output = tf.matmul(fc1_flat, W_fc1) + b_fc1\n",
    "\n",
    "        cross_entropy = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=output))\n",
    "        train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "        correct_prediction = tf.equal(tf.argmax(output,1), tf.argmax(y,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    with tf.Session( graph = g) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        t1 = time.time()\n",
    "        Initialize_time = t1-t0\n",
    "        before_test = []\n",
    "        after_test = []\n",
    "        test_accs = []\n",
    "        for i in tqdm_notebook(range(iters), desc=\"Layer1\"):\n",
    "            if i%100 == 0:\n",
    "                before_test.append(time.time())\n",
    "                test_batch = mnist.test.next_batch(1000)\n",
    "                test_accuracy = accuracy.eval(feed_dict={x:test_batch[0], y: test_batch[1], dropout: 1.0})\n",
    "                test_accs.append(test_accuracy)\n",
    "                print(\"step %d, test accuracy %g\"%(i, test_accuracy))\n",
    "                after_test.append(time.time())\n",
    "            batch = mnist.train.next_batch(50)    \n",
    "            sess.run(train_step, feed_dict={x: batch[0], y: batch[1], dropout: 0.5})\n",
    "            \n",
    "\n",
    "        print \"Final test accuracy %g\"%sess.run(accuracy, feed_dict={\n",
    "            x: mnist.test.images, y: mnist.test.labels, dropout: 1.0})\n",
    "\n",
    "        return sess.run([W_conv1, b_conv1, W_fc1, b_fc1]),test_accs,before_test,after_test,Initialize_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-28T20:37:47.794975",
     "start_time": "2017-04-28T20:37:45.535199"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Layer2(Wconv, bconv, Wfc, bfc, num_filters,iters = 100):\n",
    "    t0=time.time()\n",
    "    \n",
    "    with tf.Graph().as_default() as g:\n",
    "        x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "        D0 = tf.reshape(x, [-1,28,28,1])\n",
    "        y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "        dropout = tf.placeholder(tf.float32)\n",
    "                \n",
    "        # Pass Through\n",
    "        D1 = tf.nn.relu(conv2d(D0, Wconv, 'pass_through1') + bconv)\n",
    "        D_concat = tf.concat([D0, D1], axis=3)\n",
    "        \n",
    "        # Conv2\n",
    "        W_conv2 = weight_variable([3,3,int(D_concat.get_shape()[3]), num_filters], \"W_conv2\")\n",
    "        b_conv2 = bias_variable([num_filters], \"b_conv2\")\n",
    "        h_conv2 = tf.nn.relu(conv2d(D_concat, W_conv2, \"h_conv2\") + b_conv2)\n",
    "        h_conv2_drop = tf.nn.dropout(h_conv2, dropout)\n",
    "        \n",
    "        # FC\n",
    "        fc2_flat_1 = tf.contrib.layers.flatten(h_conv2_drop)\n",
    "        fc2_flat_2 = tf.contrib.layers.flatten(D1)\n",
    "                   \n",
    "        fc2_flat = tf.concat([fc2_flat_1,fc2_flat_2], axis=1)\n",
    "        \n",
    "        n = int(fc2_flat.get_shape()[1])\n",
    "        \n",
    "        W_fc2 = np.zeros((n, 10)).astype(np.float32)\n",
    "        W_fc2[-Wfc.shape[0]:, :] = Wfc \n",
    "        W_fc2 = tf.Variable(W_fc2)\n",
    "        \n",
    "        b_fc2 = tf.Variable(bfc)\n",
    "        \n",
    "        output = tf.matmul(fc2_flat, W_fc2) + b_fc2\n",
    "\n",
    "        cross_entropy = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=output))\n",
    "        train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "        correct_prediction = tf.equal(tf.argmax(output,1), tf.argmax(y,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "    with tf.Session( graph = g) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        t1 = time.time()\n",
    "        Initialize_time = t1-t0\n",
    "        before_test = []\n",
    "        after_test = []\n",
    "        test_accs = []\n",
    "        for i in tqdm_notebook(range(iters), desc=\"Layer2\"):\n",
    "            if i%100 == 0:\n",
    "                before_test.append(time.time())\n",
    "                test_batch = mnist.test.next_batch(1000)\n",
    "                test_accuracy = accuracy.eval(feed_dict={x:test_batch[0], y: test_batch[1], dropout: 1.0})\n",
    "                test_accs.append(test_accuracy)\n",
    "                print(\"step %d, test accuracy %g\"%(i, test_accuracy))\n",
    "                after_test.append(time.time())\n",
    "            batch = mnist.train.next_batch(50)    \n",
    "            sess.run(train_step, feed_dict={x: batch[0], y: batch[1], dropout: 0.5})\n",
    "            \n",
    "\n",
    "        print \"Final test accuracy %g\"%sess.run(accuracy, feed_dict={\n",
    "            x: mnist.test.images, y: mnist.test.labels, dropout: 1.0})\n",
    "        return sess.run([W_conv2, b_conv2, W_fc2, b_fc2]),test_accs,before_test,after_test,Initialize_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-28T20:37:55.690553",
     "start_time": "2017-04-28T20:37:54.590144"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Layer3(Wconv1, Wconv2, bconv1, bconv2, Wfc, bfc, num_filters,iters = 100):\n",
    "    t0=time.time()\n",
    "    with tf.Graph().as_default() as g:\n",
    "        x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "        D0 = tf.reshape(x, [-1,28,28,1])\n",
    "        y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "        dropout = tf.placeholder(tf.float32)\n",
    "        \n",
    "        # Pass Through\n",
    "        D1 = tf.nn.relu(conv2d(D0, Wconv1, 'pass_through1') + bconv1)\n",
    "        D2 = tf.nn.relu(conv2d(tf.concat([D0, D1], axis=3), Wconv2, 'pass_through2') + bconv2)\n",
    "        D_concat = tf.concat([D0,D1,D2], axis=3)\n",
    "        \n",
    "        # Conv3\n",
    "        W_conv3 = weight_variable([3,3,int(D_concat.get_shape()[3]), num_filters], \"W_conv3\")\n",
    "        b_conv3 = bias_variable([num_filters], \"b_conv3\")\n",
    "        h_conv3 = tf.nn.relu(conv2d(D_concat, W_conv3, \"h_conv3\") + b_conv3)\n",
    "        h_conv3_drop = tf.nn.dropout(h_conv3, dropout)\n",
    "        \n",
    "        # FC\n",
    "        fc3_flat_1 = tf.contrib.layers.flatten(h_conv3_drop)\n",
    "        fc3_flat_2 = tf.contrib.layers.flatten(D2)\n",
    "        fc3_flat_3 = tf.contrib.layers.flatten(D1)\n",
    "            \n",
    "        fc3_flat = tf.concat([fc3_flat_1, fc3_flat_2,fc3_flat_3], axis=1)\n",
    "        \n",
    "        n = int(fc3_flat.get_shape()[1])\n",
    "        \n",
    "        W_fc3 = np.zeros((n, 10)).astype(np.float32)\n",
    "        W_fc3[-Wfc.shape[0]:, :] = Wfc \n",
    "        W_fc3 = tf.Variable(W_fc3)\n",
    "        \n",
    "        b_fc3 = tf.Variable(bfc)\n",
    "        \n",
    "        output = tf.matmul(fc3_flat, W_fc3) + b_fc3\n",
    "        \n",
    "        cross_entropy = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=output))\n",
    "        train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "        correct_prediction = tf.equal(tf.argmax(output,1), tf.argmax(y,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    with tf.Session( graph = g) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        t1 = time.time()\n",
    "        Initialize_time = t1-t0\n",
    "        before_test = []\n",
    "        after_test = []\n",
    "        test_accs = []\n",
    "        for i in tqdm_notebook(range(iters), desc=\"Layer2\"):\n",
    "            if i%100 == 0:\n",
    "                before_test.append(time.time())\n",
    "                test_batch = mnist.test.next_batch(1000)\n",
    "                test_accuracy = accuracy.eval(feed_dict={x:test_batch[0], y: test_batch[1], dropout: 1.0})\n",
    "                test_accs.append(test_accuracy)\n",
    "                print(\"step %d, test accuracy %g\"%(i, test_accuracy))\n",
    "                after_test.append(time.time())\n",
    "            batch = mnist.train.next_batch(50)    \n",
    "            sess.run(train_step, feed_dict={x: batch[0], y: batch[1], dropout: 0.5})\n",
    "            \n",
    "\n",
    "        print \"Final test accuracy %g\"%sess.run(accuracy, feed_dict={\n",
    "            x: mnist.test.images, y: mnist.test.labels, dropout: 1.0})\n",
    "\n",
    "        return sess.run([W_conv3, b_conv3, W_fc3, b_fc3]),test_accs,before_test,after_test,Initialize_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_accs = []\n",
    "before_test = []\n",
    "after_test = []\n",
    "Initialize_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, test accuracy 0.1\n",
      "step 100, test accuracy 0.259\n",
      "step 200, test accuracy 0.391\n",
      "step 300, test accuracy 0.518\n",
      "step 400, test accuracy 0.62\n",
      "step 500, test accuracy 0.782\n",
      "step 600, test accuracy 0.778\n",
      "step 700, test accuracy 0.82\n",
      "step 800, test accuracy 0.882\n",
      "step 900, test accuracy 0.819\n",
      "\n",
      "Final test accuracy 0.833\n"
     ]
    }
   ],
   "source": [
    "a = Layer1(4,iters = 1000)\n",
    "D0_Wconv, D0_bconv, D0_Wfc, D0_bfc = a[0]\n",
    "test_accs += a[1]\n",
    "before_test += a[2]\n",
    "after_test += a[3]\n",
    "Initialize_time.append(a[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, test accuracy 0.851\n",
      "step 100, test accuracy 0.843\n",
      "step 200, test accuracy 0.845\n",
      "step 300, test accuracy 0.859\n",
      "step 400, test accuracy 0.877\n",
      "step 500, test accuracy 0.872\n",
      "step 600, test accuracy 0.886\n",
      "step 700, test accuracy 0.903\n",
      "step 800, test accuracy 0.88\n",
      "step 900, test accuracy 0.888\n",
      "\n",
      "Final test accuracy 0.9017\n"
     ]
    }
   ],
   "source": [
    "b = Layer2(D0_Wconv, D0_bconv, D0_Wfc, D0_bfc,4,iters=1000)\n",
    "D1_Wconv, D1_bconv, D1_Wfc, D1_bfc = b[0]\n",
    "test_accs += b[1]\n",
    "before_test += b[2]\n",
    "after_test += b[3]\n",
    "Initialize_time.append(b[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, test accuracy 0.905\n",
      "step 100, test accuracy 0.899\n",
      "step 200, test accuracy 0.904\n",
      "step 300, test accuracy 0.897\n",
      "step 400, test accuracy 0.92\n",
      "step 500, test accuracy 0.92\n",
      "step 600, test accuracy 0.915\n",
      "step 700, test accuracy 0.921\n",
      "step 800, test accuracy 0.913\n",
      "step 900, test accuracy 0.919\n",
      "\n",
      "Final test accuracy 0.9224\n"
     ]
    }
   ],
   "source": [
    "c = Layer3(D0_Wconv, D1_Wconv, D0_bconv, D1_bconv, D1_Wfc, D1_bfc,4,iters = 1000)\n",
    "D2_Wconv, D2_bconv, D2_Wfc, D2_bfc = c[0]\n",
    "test_accs += c[1]\n",
    "before_test += c[2]\n",
    "after_test += c[3]\n",
    "Initialize_time.append(c[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7iIiHqRwFxHxIIW7iIgH/X80iDyuh00SlgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e99bd90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testing_time = np.array(before_test)-np.array(after_test)\n",
    "time_since_start = np.array(before_test)+np.array(np.cumsum(testing_time))-np.array([before_test[0]])\n",
    "plt.plot(time_since_start,test_accs)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
